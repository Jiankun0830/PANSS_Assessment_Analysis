{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train['LeadStatus'] = train['LeadStatus'].replace({\"Passed\":0, \"Flagged\":1, \"Assign to CS\":1})\n",
    "test['LeadStatus'] = test['LeadStatus'].replace({\"Passed\":0, \"Flagged\":1, \"Assign to CS\":1})\n",
    "# train = train.drop(train[train['Country'] == 'ERROR'].index)\n",
    "# test = test.drop(test[test['Country'] == 'ERROR'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_last(row):\n",
    "    pId = row['PatientID']\n",
    "    # get all records of the same patient and sort by visit day.\n",
    "    patient = train[train.PatientID == pId].sort_values(by='VisitDay', ascending=True).reset_index(drop=True)\n",
    "    if patient.shape[0] == 0:\n",
    "        patient = test[test.PatientID == pId].sort_values(by='VisitDay', ascending=True).reset_index(drop=True)\n",
    "    # get the index of the record that current row represents\n",
    "    current = patient[patient.VisitDay == row['VisitDay']].index.values[0]\n",
    "    if current == 0: # if it's the first time visiting\n",
    "        return 0\n",
    "    else: # return the difference between the current panss total and last time panss total.\n",
    "        return row['PANSS_Total'] - patient.loc[current-1,'PANSS_Total']\n",
    "    \n",
    "\n",
    "train_comp_last = train.copy()\n",
    "test_comp_last = test.copy()\n",
    "train_comp_last['TotalCompareLastTime'] = train_comp_last.apply(compare_last, axis=1)\n",
    "test_comp_last['TotalCompareLastTime'] = test_comp_last.apply(compare_last, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 7:38]\n",
    "X_test = test.iloc[:, 7:38]\n",
    "\n",
    "y_train = train['LeadStatus']\n",
    "y_test = test['LeadStatus']\n",
    "\n",
    "X_colnames = train.columns[7:38]\n",
    "X_train_org = train.values[:, 7:38]\n",
    "X_test_org = test.values[:, 7:38]\n",
    "\n",
    "X_train_delta = pd.concat([X_train,train_comp_last.TotalCompareLastTime], axis=1)\n",
    "X_test_delta = pd.concat([X_test,test_comp_last.TotalCompareLastTime], axis=1)\n",
    "\n",
    "\n",
    "# upsamling minority class\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "not_fraud = X[X['LeadStatus']==0]\n",
    "fraud = X[X['LeadStatus']==1]\n",
    "\n",
    "fraud_upsampled = resample(fraud,\n",
    "                           replace=True, # sample with replacement\n",
    "                           n_samples=len(not_fraud), # match number in majority class\n",
    "                           random_state=27) # reproducible results\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "y_train_upsampled = upsampled.LeadStatus\n",
    "X_train_upsampled = upsampled.drop('LeadStatus', axis=1)\n",
    "\n",
    "X = pd.concat([X_train_delta, y_train], axis=1)\n",
    "\n",
    "not_fraud = X[X['LeadStatus']==0]\n",
    "fraud = X[X['LeadStatus']==1]\n",
    "\n",
    "fraud_upsampled = resample(fraud,\n",
    "                           replace=True, # sample with replacement\n",
    "                           n_samples=len(not_fraud), # match number in majority class\n",
    "                           random_state=27) # reproducible results\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "y_train_delta_upsampled = upsampled.LeadStatus\n",
    "X_train_delta_upsampled = upsampled.drop('LeadStatus', axis=1)\n",
    "\n",
    "# Standarization\n",
    "ss_X = StandardScaler()\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.fit_transform(X_test)\n",
    "X_test_delta = ss_X.fit_transform(X_test_delta)\n",
    "X_train_upsampled = ss_X.fit_transform(X_train_upsampled)\n",
    "X_train_delta = ss_X.fit_transform(X_train_delta)\n",
    "X_train_delta_upsampled = ss_X.fit_transform(X_train_delta_upsampled)\n",
    "\n",
    "\n",
    "\n",
    "#PCA\n",
    "decomposer = PCA(n_components=20, random_state=42,)\n",
    "X_train_comp = decomposer.fit_transform(X_train)\n",
    "X_train_upsampled_comp = decomposer.fit_transform(X_train_upsampled)\n",
    "X_test_comp = decomposer.fit_transform(X_test)\n",
    "\n",
    "X_test_comp = X_test_comp[:,decomposer.explained_variance_ratio_>0.02]\n",
    "X_train_comp = X_train_comp[:,decomposer.explained_variance_ratio_>0.02]\n",
    "X_train_upsampled_comp = X_train_upsampled_comp[:,decomposer.explained_variance_ratio_>0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16799, 31)\n",
      "(25430, 31)\n",
      "(16799, 32)\n",
      "(25430, 32)\n",
      "(4148, 31)\n",
      "(4148, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_upsampled.shape)\n",
    "print(X_train_delta.shape)\n",
    "print(X_train_delta_upsampled.shape)\n",
    "print(X_test.shape)\n",
    "print(X_test_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, x_train, y_train, x_test, y_test):\n",
    "    '''\n",
    "    x_train: pd.DataFrame\n",
    "    y_train: pd.Series\n",
    "    return: None\n",
    "    print: precision, recall, f1, accuracy\n",
    "    '''\n",
    "    from warnings import simplefilter\n",
    "    import time\n",
    "    simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    stop = time.time()\n",
    "    print('Training took {:3.2f} seconds.'.format(stop-start))\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Index(['VisitDay', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'N1', 'N2', 'N3',\n",
      "       'N4', 'N5', 'N6', 'N7', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8',\n",
      "       'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15', 'G16'],\n",
      "      dtype='object').\n",
      "\n",
      "standarization\n",
      "Logistic Regression\n",
      "Training took 0.08 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86      3126\n",
      "           1       0.62      0.10      0.17      1022\n",
      "\n",
      "    accuracy                           0.76      4148\n",
      "   macro avg       0.70      0.54      0.51      4148\n",
      "weighted avg       0.73      0.76      0.69      4148\n",
      "\n",
      "Naive Bayes\n",
      "Training took 0.01 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      3126\n",
      "           1       0.40      0.41      0.40      1022\n",
      "\n",
      "    accuracy                           0.70      4148\n",
      "   macro avg       0.60      0.60      0.60      4148\n",
      "weighted avg       0.70      0.70      0.70      4148\n",
      "\n",
      "Random Forest\n",
      "Training took 0.13 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      3126\n",
      "           1       0.47      0.16      0.24      1022\n",
      "\n",
      "    accuracy                           0.75      4148\n",
      "   macro avg       0.62      0.55      0.55      4148\n",
      "weighted avg       0.70      0.75      0.70      4148\n",
      "\n",
      "SVM\n",
      "Training took 8.51 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87      3126\n",
      "           1       0.66      0.19      0.30      1022\n",
      "\n",
      "    accuracy                           0.78      4148\n",
      "   macro avg       0.72      0.58      0.58      4148\n",
      "weighted avg       0.75      0.78      0.73      4148\n",
      "\n",
      "KNN\n",
      "Training took 0.12 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      3126\n",
      "           1       0.41      0.23      0.30      1022\n",
      "\n",
      "    accuracy                           0.73      4148\n",
      "   macro avg       0.60      0.56      0.57      4148\n",
      "weighted avg       0.69      0.73      0.70      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'SVM', 'KNN']\n",
    "models = [LogisticRegression(), GaussianNB(), RandomForestClassifier(), SVC(), KNeighborsClassifier(n_neighbors=5)]\n",
    "print(\"Features: {}.\\n\".format(X_colnames))\n",
    "print(\"standarization\")\n",
    "for i in range(len(model_names)):\n",
    "    print(model_names[i])\n",
    "    fit_model(models[i], X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Index(['VisitDay', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'N1', 'N2', 'N3',\n",
      "       'N4', 'N5', 'N6', 'N7', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8',\n",
      "       'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15', 'G16'],\n",
      "      dtype='object').\n",
      "\n",
      "delta\n",
      "Logistic Regression\n",
      "Training took 0.05 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86      3126\n",
      "           1       0.62      0.10      0.17      1022\n",
      "\n",
      "    accuracy                           0.76      4148\n",
      "   macro avg       0.70      0.54      0.51      4148\n",
      "weighted avg       0.73      0.76      0.69      4148\n",
      "\n",
      "Naive Bayes\n",
      "Training took 0.01 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      3126\n",
      "           1       0.40      0.41      0.40      1022\n",
      "\n",
      "    accuracy                           0.70      4148\n",
      "   macro avg       0.60      0.60      0.60      4148\n",
      "weighted avg       0.71      0.70      0.70      4148\n",
      "\n",
      "Random Forest\n",
      "Training took 0.15 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      3126\n",
      "           1       0.55      0.20      0.30      1022\n",
      "\n",
      "    accuracy                           0.76      4148\n",
      "   macro avg       0.67      0.57      0.58      4148\n",
      "weighted avg       0.73      0.76      0.72      4148\n",
      "\n",
      "SVM\n",
      "Training took 8.57 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87      3126\n",
      "           1       0.63      0.20      0.30      1022\n",
      "\n",
      "    accuracy                           0.77      4148\n",
      "   macro avg       0.71      0.58      0.59      4148\n",
      "weighted avg       0.75      0.77      0.73      4148\n",
      "\n",
      "KNN\n",
      "Training took 0.03 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84      3126\n",
      "           1       0.43      0.23      0.30      1022\n",
      "\n",
      "    accuracy                           0.73      4148\n",
      "   macro avg       0.61      0.57      0.57      4148\n",
      "weighted avg       0.70      0.73      0.71      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'SVM', 'KNN']\n",
    "models = [LogisticRegression(), GaussianNB(), RandomForestClassifier(), SVC(), KNeighborsClassifier(n_neighbors=5)]\n",
    "print(\"Features: {}.\\n\".format(X_colnames))\n",
    "print(\"delta\")\n",
    "for i in range(len(model_names)):\n",
    "    print(model_names[i])\n",
    "    fit_model(models[i], X_train_delta, y_train, X_test_delta, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Index(['VisitDay', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'N1', 'N2', 'N3',\n",
      "       'N4', 'N5', 'N6', 'N7', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8',\n",
      "       'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15', 'G16'],\n",
      "      dtype='object').\n",
      "\n",
      "with delta and upsampling\n",
      "Logistic Regression\n",
      "Training took 0.07 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67      3126\n",
      "           1       0.33      0.67      0.44      1022\n",
      "\n",
      "    accuracy                           0.58      4148\n",
      "   macro avg       0.58      0.61      0.56      4148\n",
      "weighted avg       0.71      0.58      0.61      4148\n",
      "\n",
      "Naive Bayes\n",
      "Training took 0.01 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.74      3126\n",
      "           1       0.36      0.55      0.43      1022\n",
      "\n",
      "    accuracy                           0.65      4148\n",
      "   macro avg       0.59      0.61      0.59      4148\n",
      "weighted avg       0.71      0.65      0.67      4148\n",
      "\n",
      "Random Forest\n",
      "Training took 0.19 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      3126\n",
      "           1       0.49      0.23      0.31      1022\n",
      "\n",
      "    accuracy                           0.75      4148\n",
      "   macro avg       0.64      0.58      0.58      4148\n",
      "weighted avg       0.71      0.75      0.72      4148\n",
      "\n",
      "SVM\n",
      "Training took 27.82 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78      3126\n",
      "           1       0.42      0.61      0.50      1022\n",
      "\n",
      "    accuracy                           0.70      4148\n",
      "   macro avg       0.63      0.67      0.64      4148\n",
      "weighted avg       0.74      0.70      0.71      4148\n",
      "\n",
      "KNN\n",
      "Training took 0.07 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.66      0.73      3126\n",
      "           1       0.33      0.52      0.40      1022\n",
      "\n",
      "    accuracy                           0.62      4148\n",
      "   macro avg       0.57      0.59      0.57      4148\n",
      "weighted avg       0.69      0.62      0.65      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'SVM', 'KNN']\n",
    "models = [LogisticRegression(), GaussianNB(), RandomForestClassifier(), SVC(), KNeighborsClassifier(n_neighbors=5)]\n",
    "print(\"Features: {}.\\n\".format(X_colnames))\n",
    "print(\"delta and upsampling\")\n",
    "for i in range(len(model_names)):\n",
    "    print(model_names[i])\n",
    "    fit_model(models[i], X_train_delta_upsampled, y_train_upsampled, X_test_delta, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Index(['VisitDay', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'N1', 'N2', 'N3',\n",
      "       'N4', 'N5', 'N6', 'N7', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8',\n",
      "       'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15', 'G16'],\n",
      "      dtype='object').\n",
      "\n",
      "Class Weight\n",
      "Logistic Regression\n",
      "Training took 0.05 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.72      3126\n",
      "           1       0.35      0.58      0.44      1022\n",
      "\n",
      "    accuracy                           0.63      4148\n",
      "   macro avg       0.59      0.61      0.58      4148\n",
      "weighted avg       0.71      0.63      0.65      4148\n",
      "\n",
      "SVM\n",
      "Training took 11.73 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79      3126\n",
      "           1       0.44      0.61      0.51      1022\n",
      "\n",
      "    accuracy                           0.71      4148\n",
      "   macro avg       0.64      0.68      0.65      4148\n",
      "weighted avg       0.75      0.71      0.72      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['Logistic Regression', 'SVM']\n",
    "models = [LogisticRegression(class_weight = {1:0.75,0:0.25}), SVC(class_weight = {1:0.75,0:0.25})]\n",
    "print(\"Features: {}.\\n\".format(X_colnames))\n",
    "print(\"Class Weight\")\n",
    "for i in range(len(model_names)):\n",
    "    print(model_names[i])\n",
    "    fit_model(models[i], X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Index(['VisitDay', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'N1', 'N2', 'N3',\n",
      "       'N4', 'N5', 'N6', 'N7', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8',\n",
      "       'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15', 'G16'],\n",
      "      dtype='object').\n",
      "\n",
      "upsampled + standarization\n",
      "Logistic Regression\n",
      "Training took 0.07 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67      3126\n",
      "           1       0.33      0.67      0.44      1022\n",
      "\n",
      "    accuracy                           0.59      4148\n",
      "   macro avg       0.58      0.61      0.56      4148\n",
      "weighted avg       0.71      0.59      0.61      4148\n",
      "\n",
      "Naive Bayes\n",
      "Training took 0.01 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.74      3126\n",
      "           1       0.35      0.54      0.43      1022\n",
      "\n",
      "    accuracy                           0.64      4148\n",
      "   macro avg       0.59      0.61      0.58      4148\n",
      "weighted avg       0.70      0.64      0.66      4148\n",
      "\n",
      "Random Forest\n",
      "Training took 0.18 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85      3126\n",
      "           1       0.48      0.22      0.30      1022\n",
      "\n",
      "    accuracy                           0.75      4148\n",
      "   macro avg       0.63      0.57      0.58      4148\n",
      "weighted avg       0.71      0.75      0.71      4148\n",
      "\n",
      "SVM\n",
      "Training took 29.74 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78      3126\n",
      "           1       0.41      0.59      0.48      1022\n",
      "\n",
      "    accuracy                           0.69      4148\n",
      "   macro avg       0.62      0.65      0.63      4148\n",
      "weighted avg       0.74      0.69      0.70      4148\n",
      "\n",
      "KNN\n",
      "Training took 0.07 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72      3126\n",
      "           1       0.33      0.51      0.40      1022\n",
      "\n",
      "    accuracy                           0.62      4148\n",
      "   macro avg       0.57      0.58      0.56      4148\n",
      "weighted avg       0.69      0.62      0.64      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'SVM', 'KNN']\n",
    "models = [LogisticRegression(), GaussianNB(), RandomForestClassifier(), SVC(), KNeighborsClassifier(n_neighbors=5)]\n",
    "print(\"Features: {}.\\n\".format(X_colnames))\n",
    "print(\"upsampled + standarization\")\n",
    "for i in range(len(model_names)):\n",
    "    print(model_names[i])\n",
    "    fit_model(models[i], X_train_upsampled, y_train_upsampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Index(['VisitDay', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'N1', 'N2', 'N3',\n",
      "       'N4', 'N5', 'N6', 'N7', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8',\n",
      "       'G9', 'G10', 'G11', 'G12', 'G13', 'G14', 'G15', 'G16'],\n",
      "      dtype='object').\n",
      "\n",
      "PCA\n",
      "Logistic Regression\n",
      "Training took 0.02 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85      3126\n",
      "           1       0.37      0.05      0.09      1022\n",
      "\n",
      "    accuracy                           0.74      4148\n",
      "   macro avg       0.56      0.51      0.47      4148\n",
      "weighted avg       0.66      0.74      0.66      4148\n",
      "\n",
      "Naive Bayes\n",
      "Training took 0.00 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84      3126\n",
      "           1       0.44      0.20      0.28      1022\n",
      "\n",
      "    accuracy                           0.74      4148\n",
      "   macro avg       0.61      0.56      0.56      4148\n",
      "weighted avg       0.69      0.74      0.70      4148\n",
      "\n",
      "Random Forest\n",
      "Training took 0.34 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84      3126\n",
      "           1       0.30      0.09      0.14      1022\n",
      "\n",
      "    accuracy                           0.72      4148\n",
      "   macro avg       0.53      0.51      0.49      4148\n",
      "weighted avg       0.64      0.72      0.66      4148\n",
      "\n",
      "SVM\n",
      "Training took 5.58 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      3126\n",
      "           1       0.34      0.09      0.14      1022\n",
      "\n",
      "    accuracy                           0.73      4148\n",
      "   macro avg       0.55      0.52      0.49      4148\n",
      "weighted avg       0.66      0.73      0.67      4148\n",
      "\n",
      "KNN\n",
      "Training took 0.01 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81      3126\n",
      "           1       0.30      0.18      0.23      1022\n",
      "\n",
      "    accuracy                           0.69      4148\n",
      "   macro avg       0.53      0.52      0.52      4148\n",
      "weighted avg       0.65      0.69      0.67      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'SVM', 'KNN']\n",
    "models = [LogisticRegression(), GaussianNB(), RandomForestClassifier(), SVC(), KNeighborsClassifier(n_neighbors=5)]\n",
    "print(\"Features: {}.\\n\".format(X_colnames))\n",
    "print(\"PCA\")\n",
    "for i in range(len(model_names)):\n",
    "    print(model_names[i])\n",
    "    fit_model(models[i], X_train_comp, y_train, X_test_comp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_upsampled, y_train_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_para = {'n_estimators': 240,\n",
    "             'min_samples_split': 10,\n",
    "             'min_samples_leaf': 4,\n",
    "             'max_features': 'sqrt',\n",
    "             'max_depth': 90,\n",
    "             'bootstrap': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [200, 250, 300, 350],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [3, 4, 5],\n",
       "                         'n_estimators': [200, 250, 300, 350, 400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [200,250,300,350],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'n_estimators': [200, 250, 300, 350, 400]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                           cv = 3, n_jobs = -1, verbose = 2, scoring='f1')\n",
    "grid_search.fit(X_train_delta_upsampled, y_train_delta_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_para = {'bootstrap': True,\n",
    "             'max_depth': 300,\n",
    "             'max_features': 'sqrt',\n",
    "             'min_samples_leaf': 3,\n",
    "             'min_samples_split': 8,\n",
    "             'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      3126\n",
      "           1       0.55      0.38      0.45      1022\n",
      "\n",
      "    accuracy                           0.77      4148\n",
      "   macro avg       0.69      0.64      0.65      4148\n",
      "weighted avg       0.75      0.77      0.76      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best_para = grid_search.best_params_\n",
    "best_para = {'bootstrap': True,\n",
    "             'max_depth': 300,\n",
    "             'max_features': 'sqrt',\n",
    "             'min_samples_leaf': 3,\n",
    "             'min_samples_split': 8,\n",
    "             'n_estimators': 300}\n",
    "rf = RandomForestClassifier()\n",
    "rf.set_params(**best_para)\n",
    "rf.fit(X_train_delta_upsampled, y_train_delta_upsampled)\n",
    "y_pred = rf.predict(X_test_delta)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = list(range(1,50))\n",
    "train_results = []\n",
    "train_results_f1 = []\n",
    "test_results = []\n",
    "test_results_f1 = []\n",
    "\n",
    "for n in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train_delta_upsampled, y_train_delta_upsampled)\n",
    "    train_pred = knn.predict(X_train_delta)\n",
    "    \n",
    "    f1 = f1_score(y_train, train_pred)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    train_results_f1.append(f1)\n",
    "    \n",
    "    y_pred = knn.predict(X_test_delta)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "    test_results_f1.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line1, = plt.plot(neighbors, train_results,  c='b', label='Train AUC')\n",
    "line2, = plt.plot(neighbors, test_results, c='r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.savefig('plots/KNN_AUC_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line1, = plt.plot(neighbors, train_results_f1, c='b', label='Train F1')\n",
    "line2, = plt.plot(neighbors, test_results_f1, c='r', label='Test F1')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.savefig('plots/KNN_F1_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.628945351968779\n",
      "38\n",
      "0.45258783528522856\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(max(test_results))\n",
    "print(test_results.index(max(test_results)))\n",
    "print(max(test_results_f1))\n",
    "print(test_results_f1.index(max(test_results_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75      3126\n",
      "           1       0.37      0.56      0.45      1022\n",
      "\n",
      "    accuracy                           0.66      4148\n",
      "   macro avg       0.60      0.63      0.60      4148\n",
      "weighted avg       0.72      0.66      0.68      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=38)\n",
    "knn.fit(X_train_delta_upsampled, y_train_delta_upsampled)\n",
    "y_pred = knn.predict(X_test_delta)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/home/jiankun/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1],\n",
       "                         'class_weight': [{0: 25, 1: 0.75}], 'gamma': ['scale'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = [0.01, 0.1, 1]\n",
    "gammas = ['scale']\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "class_weights = [{1:0.75, 0:25}]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas, 'kernel':kernels, 'class_weight':class_weights}\n",
    "\n",
    "svm = SVC()\n",
    "# Instantiate the grid search model\n",
    "grid_svm = GridSearchCV(estimator = svm, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2, scoring='f1')\n",
    "grid_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': {1: 0.75, 0: 25}, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3126\n",
      "           1       0.69      0.03      0.06      1022\n",
      "\n",
      "    accuracy                           0.76      4148\n",
      "   macro avg       0.73      0.51      0.46      4148\n",
      "weighted avg       0.74      0.76      0.66      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_para = grid_svm.best_params_\n",
    "print(best_para)\n",
    "svm = SVC()\n",
    "svm.set_params(**best_para)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86      3126\n",
      "           1       0.00      0.00      0.00      1022\n",
      "\n",
      "    accuracy                           0.75      4148\n",
      "   macro avg       0.38      0.50      0.43      4148\n",
      "weighted avg       0.57      0.75      0.65      4148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiankun/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.68      0.75      3126\n",
      "           1       0.36      0.56      0.44      1022\n",
      "\n",
      "    accuracy                           0.65      4148\n",
      "   macro avg       0.60      0.62      0.59      4148\n",
      "weighted avg       0.71      0.65      0.67      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(class_weight = {1:0.75,0:0.25},kernel = 'linear')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79      3126\n",
      "           1       0.44      0.61      0.51      1022\n",
      "\n",
      "    accuracy                           0.71      4148\n",
      "   macro avg       0.64      0.68      0.65      4148\n",
      "weighted avg       0.75      0.71      0.72      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(class_weight = {1:0.75,0:0.25},kernel = 'rbf')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  24 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.6s finished\n",
      "/home/jiankun/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C_param_range = [0.001,0.1,1,10]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C_param_range, penalty=penalty)\n",
    "\n",
    "logi = LogisticRegression()\n",
    "# Instantiate the grid search model\n",
    "grid_logi = GridSearchCV(estimator = logi, param_grid = hyperparameters, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2, scoring='roc_auc')\n",
    "grid_logi.fit(X_train_delta_upsampled, y_train_delta_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67      3126\n",
      "           1       0.33      0.67      0.44      1022\n",
      "\n",
      "    accuracy                           0.59      4148\n",
      "   macro avg       0.58      0.61      0.56      4148\n",
      "weighted avg       0.71      0.59      0.61      4148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiankun/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "best_para = grid_logi.best_params_\n",
    "print(best_para)\n",
    "lg = LogisticRegression()\n",
    "lg.set_params(**best_para)\n",
    "lg.fit(X_train_delta_upsampled, y_train_delta_upsampled)\n",
    "y_pred = lg.predict(X_test_delta)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight={0: 0.25, 1: 0.75}, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(class_weight = {1:0.75,0:0.25},probability=True)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = pd.read_csv('../data/Study_E.csv')\n",
    "X_E = E.iloc[:, 7:38]\n",
    "X_E = ss_X.fit_transform(X_E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_E)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssessmentID</th>\n",
       "      <th>LeadStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500679</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500930</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>502177</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501533</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AssessmentID  LeadStatus\n",
       "0        501017         0.0\n",
       "1        500679         0.0\n",
       "2        500930         0.0\n",
       "3        502177         0.0\n",
       "4        501533         0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out['AssessmentID']=E['AssessmentiD']\n",
    "df_out['LeadStatus'] = y_pred\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
